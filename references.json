[
  {
    "id": "4vnyY9J9",
    "type": "paper-conference",
    "title": "Interpretable Unsupervised Diversity Denoising and Artefact Removal",
    "container-title": "Proceedings of the Tenth International Conference on Learning Representations",
    "URL": "https://proceedings.mlr.press/v143/lalit21a.html",
    "author": [
      {
        "family": "Prakash",
        "given": "Mangal"
      },
      {
        "family": "Delbracio",
        "given": "Mauricio"
      },
      {
        "family": "Milanfar",
        "given": "Peyman"
      },
      {
        "family": "Jug",
        "given": "Florian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2022",
          6,
          26
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: HDN"
  },
  {
    "id": "EcizztLg",
    "type": "webpage",
    "title": "MMSegmentation: OpenMMLab Semantic Segmentation Toolbox and Benchmark",
    "URL": "https://github.com/open-mmlab/mmsegmentation",
    "publisher": "Github",
    "author": [
      {
        "family": "Contributors",
        "given": "MMSegmentation"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          12,
          12
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: MMSegmentation"
  },
  {
    "id": "gsfWGJKf",
    "type": "webpage",
    "title": "AICSImageIO: Image Reading, Metadata Conversion, and Image Writing for Microscopy Images in Pure Python",
    "URL": "https://github.com/AllenCellModeling/aicsimageio",
    "publisher": "Github",
    "author": [
      {
        "family": "Brown",
        "given": "Eva Maxfield"
      },
      {
        "family": "Toloudis",
        "given": "Dan"
      },
      {
        "family": "Sherman",
        "given": "Jamie"
      },
      {
        "family": "Swain-Bowden",
        "given": "Madison"
      },
      {
        "family": "Lambert",
        "given": "Talley"
      },
      {
        "family": "AICSImageIO Contributors",
        "given": " "
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          4,
          1
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: aicsimageio"
  },
  {
    "id": "OCow1hly",
    "type": "paper-conference",
    "title": "Attention U-Net: Learning Where to Look for the Pancreas",
    "container-title": "Proceedings of Medical Imaging with Deep Learning 2018",
    "URL": "https://openreview.net/forum?id=Skft7cijM",
    "author": [
      {
        "family": "Oktay",
        "given": "Ozan"
      },
      {
        "family": "Schlemper",
        "given": "Jo"
      },
      {
        "family": "Le Folgoc",
        "given": "Loic"
      },
      {
        "family": "Lee",
        "given": "Matthew"
      },
      {
        "family": "Heinrich",
        "given": "Matthias"
      },
      {
        "family": "Misawa",
        "given": "Kazunari"
      },
      {
        "family": "Mori",
        "given": "Kensaku"
      },
      {
        "family": "McDonagh",
        "given": "Steven"
      },
      {
        "family": "Hammerla",
        "given": "Nils Y."
      },
      {
        "family": "Kainz",
        "given": "Bernhard"
      },
      {
        "family": "Glocker",
        "given": "Ben"
      },
      {
        "family": "Rueckert",
        "given": "Daniel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2022",
          6,
          24
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: attentionUnet"
  },
  {
    "id": "zvJ4kB9e",
    "type": "webpage",
    "title": "Broad Bioimage Benchmark Collection: C. elegangs live/dead assay",
    "URL": "https://bbbc.broadinstitute.org/BBBC010",
    "author": [
      {
        "family": "Ausubel",
        "given": "Fred"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          12,
          18
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: broad"
  },
  {
    "id": "b6GmFJlO",
    "type": "webpage",
    "title": "Content Aware Image Restoration: Pushing the Limits of Fluorescence Microscopy - Supplemental Data",
    "URL": "https://publications.mpi-cbg.de/publications-sites/7207/",
    "author": [
      {
        "family": "Weigert",
        "given": "Martin"
      },
      {
        "family": "Schmidt",
        "given": "Uwe"
      },
      {
        "family": "Boothe",
        "given": "Tobias"
      },
      {
        "family": "Müller",
        "given": "Andreas"
      },
      {
        "family": "Dibrov",
        "given": "Alexandr"
      },
      {
        "family": "Jain",
        "given": "Akanksha"
      },
      {
        "family": "Wilhelm",
        "given": "Benjamin"
      },
      {
        "family": "Schmidt",
        "given": "Deborah"
      },
      {
        "family": "Broaddus",
        "given": "Coleman"
      },
      {
        "family": "Culley",
        "given": "Sian"
      },
      {
        "family": "Myers",
        "given": " ... Eugene W."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          12,
          18
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: denoising"
  },
  {
    "publisher": "Springer International Publishing",
    "DOI": "10.1007/978-3-030-00934-2_30",
    "type": "chapter",
    "page": "265-273",
    "source": "Crossref",
    "title": "Cell Detection with Star-Convex Polygons",
    "author": [
      {
        "given": "Uwe",
        "family": "Schmidt"
      },
      {
        "given": "Martin",
        "family": "Weigert"
      },
      {
        "given": "Coleman",
        "family": "Broaddus"
      },
      {
        "given": "Gene",
        "family": "Myers"
      }
    ],
    "container-title": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2018",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "URL": "https://doi.org/ggnzqb",
    "id": "tIIG2f8K",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1007/978-3-030-00934-2_30"
  },
  {
    "publisher": "Springer International Publishing",
    "DOI": "10.1007/978-3-030-12029-0_40",
    "type": "chapter",
    "page": "371-380",
    "source": "Crossref",
    "title": "Left-Ventricle Quantification Using Residual U-Net",
    "author": [
      {
        "given": "Eric",
        "family": "Kerfoot"
      },
      {
        "given": "James",
        "family": "Clough"
      },
      {
        "given": "Ilkay",
        "family": "Oksuz"
      },
      {
        "given": "Jack",
        "family": "Lee"
      },
      {
        "given": "Andrew P.",
        "family": "King"
      },
      {
        "given": "Julia A.",
        "family": "Schnabel"
      }
    ],
    "container-title": "Statistical Atlases and Computational Models of the Heart. Atrial Segmentation and LV Quantification Challenges",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "URL": "https://doi.org/gqdkdp",
    "id": "M7480NLD",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1007/978-3-030-12029-0_40"
  },
  {
    "publisher": "Springer International Publishing",
    "DOI": "10.1007/978-3-031-08999-2_22",
    "type": "chapter",
    "page": "272-284",
    "source": "Crossref",
    "title": "Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images",
    "author": [
      {
        "given": "Ali",
        "family": "Hatamizadeh"
      },
      {
        "given": "Vishwesh",
        "family": "Nath"
      },
      {
        "given": "Yucheng",
        "family": "Tang"
      },
      {
        "given": "Dong",
        "family": "Yang"
      },
      {
        "given": "Holger R.",
        "family": "Roth"
      },
      {
        "given": "Daguang",
        "family": "Xu"
      }
    ],
    "container-title": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "URL": "https://doi.org/gqrg93",
    "id": "ZWL3IrVc",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1007/978-3-031-08999-2_22"
  },
  {
    "publisher": "Springer Nature Switzerland",
    "DOI": "10.1007/978-3-031-16440-8_10",
    "type": "chapter",
    "page": "99-108",
    "source": "Crossref",
    "title": "DeStripe: A Self2Self Spatio-Spectral Graph Neural Network with Unfolded Hessian for Stripe Artifact Removal in Light-Sheet Microscopy",
    "author": [
      {
        "given": "Yu",
        "family": "Liu"
      },
      {
        "given": "Kurt",
        "family": "Weiss"
      },
      {
        "given": "Nassir",
        "family": "Navab"
      },
      {
        "given": "Carsten",
        "family": "Marr"
      },
      {
        "given": "Jan",
        "family": "Huisken"
      },
      {
        "given": "Tingying",
        "family": "Peng"
      }
    ],
    "container-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "URL": "https://doi.org/grxqnw",
    "id": "tuObtXMR",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1007/978-3-031-16440-8_10"
  },
  {
    "publisher": "Springer International Publishing",
    "DOI": "10.1007/978-3-319-24574-4_28",
    "type": "chapter",
    "page": "234-241",
    "source": "Crossref",
    "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
    "author": [
      {
        "given": "Olaf",
        "family": "Ronneberger"
      },
      {
        "given": "Philipp",
        "family": "Fischer"
      },
      {
        "given": "Thomas",
        "family": "Brox"
      }
    ],
    "container-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "URL": "https://doi.org/gcgk7j",
    "id": "TutLhFSz",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1007/978-3-319-24574-4_28"
  },
  {
    "publisher": "Elsevier BV",
    "DOI": "10.1016/j.media.2016.08.008",
    "type": "article-journal",
    "page": "489-502",
    "source": "Crossref",
    "title": "Gland segmentation in colon histology images: The glas challenge contest",
    "volume": "35",
    "author": [
      {
        "given": "Korsuk",
        "family": "Sirinukunwattana"
      },
      {
        "given": "Josien P.W.",
        "family": "Pluim"
      },
      {
        "given": "Hao",
        "family": "Chen"
      },
      {
        "given": "Xiaojuan",
        "family": "Qi"
      },
      {
        "given": "Pheng-Ann",
        "family": "Heng"
      },
      {
        "given": "Yun Bo",
        "family": "Guo"
      },
      {
        "given": "Li Yang",
        "family": "Wang"
      },
      {
        "given": "Bogdan J.",
        "family": "Matuszewski"
      },
      {
        "given": "Elia",
        "family": "Bruni"
      },
      {
        "given": "Urko",
        "family": "Sanchez"
      },
      {
        "given": "Anton",
        "family": "Böhm"
      },
      {
        "given": "Olaf",
        "family": "Ronneberger"
      },
      {
        "given": "Bassem Ben",
        "family": "Cheikh"
      },
      {
        "given": "Daniel",
        "family": "Racoceanu"
      },
      {
        "given": "Philipp",
        "family": "Kainz"
      },
      {
        "given": "Michael",
        "family": "Pfeiffer"
      },
      {
        "given": "Martin",
        "family": "Urschler"
      },
      {
        "given": "David R.J.",
        "family": "Snead"
      },
      {
        "given": "Nasir M.",
        "family": "Rajpoot"
      }
    ],
    "container-title": "Medical Image Analysis",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2017,
          1
        ]
      ]
    },
    "URL": "https://doi.org/c5t7",
    "container-title-short": "Medical Image Analysis",
    "id": "XAffSYIR",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1016/j.media.2016.08.008"
  },
  {
    "publisher": "Elsevier BV",
    "DOI": "10.1016/j.media.2022.102523",
    "type": "article-journal",
    "page": "102523",
    "source": "Crossref",
    "title": "EmbedSeg: Embedding-based Instance Segmentation for Biomedical Microscopy Data",
    "volume": "81",
    "author": [
      {
        "given": "Manan",
        "family": "Lalit"
      },
      {
        "given": "Pavel",
        "family": "Tomancak"
      },
      {
        "given": "Florian",
        "family": "Jug"
      }
    ],
    "container-title": "Medical Image Analysis",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          10
        ]
      ]
    },
    "URL": "https://doi.org/grxbwr",
    "container-title-short": "Medical Image Analysis",
    "id": "K2ugNcVa",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1016/j.media.2022.102523"
  },
  {
    "publisher": "American Chemical Society (ACS)",
    "issue": "7",
    "DOI": "10.1021/cb900084v",
    "type": "article-journal",
    "page": "527-533",
    "source": "Crossref",
    "title": "High-Throughput Screen for Novel Antimicrobials using a Whole Animal Infection Model",
    "volume": "4",
    "author": [
      {
        "given": "Terence I.",
        "family": "Moy"
      },
      {
        "given": "Annie L.",
        "family": "Conery"
      },
      {
        "given": "Jonah",
        "family": "Larkins-Ford"
      },
      {
        "given": "Gang",
        "family": "Wu"
      },
      {
        "given": "Ralph",
        "family": "Mazitschek"
      },
      {
        "given": "Gabriele",
        "family": "Casadei"
      },
      {
        "given": "Kim",
        "family": "Lewis"
      },
      {
        "given": "Anne E.",
        "family": "Carpenter"
      },
      {
        "given": "Frederick M.",
        "family": "Ausubel"
      }
    ],
    "container-title": "ACS Chemical Biology",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2009,
          6,
          29
        ]
      ]
    },
    "URL": "https://doi.org/bdwdfc",
    "container-title-short": "ACS Chem. Biol.",
    "PMCID": "PMC2745594",
    "PMID": "19572548",
    "id": "138foKNOh",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1021/cb900084v"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "7",
    "DOI": "10.1038/nmeth.2083",
    "type": "article-journal",
    "page": "637-637",
    "source": "Crossref",
    "title": "Annotated high-throughput microscopy image sets for validation",
    "volume": "9",
    "author": [
      {
        "given": "Vebjorn",
        "family": "Ljosa"
      },
      {
        "given": "Katherine L",
        "family": "Sokolnicki"
      },
      {
        "given": "Anne E",
        "family": "Carpenter"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2012,
          6,
          28
        ]
      ]
    },
    "URL": "https://doi.org/gf6hxm",
    "container-title-short": "Nat Methods",
    "PMCID": "PMC3627348",
    "PMID": "22743765",
    "id": "wJGDcP0t",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/nmeth.2083"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "7943",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Understanding how a subset of expressed genes dictates cellular phenotype is a considerable challenge owing to the large numbers of molecules involved, their combinatorics and the plethora of cellular behaviours that they determine<jats:sup>1,2</jats:sup>. Here we reduced this complexity by focusing on cellular organization—a key readout and driver of cell behaviour<jats:sup>3,4</jats:sup>—at the level of major cellular structures that represent distinct organelles and functional machines, and generated the WTC-11 hiPSC Single-Cell Image Dataset v1, which contains more than 200,000 live cells in 3D, spanning 25 key cellular structures. The scale and quality of this dataset permitted the creation of a generalizable analysis framework to convert raw image data of cells and their structures into dimensionally reduced, quantitative measurements that can be interpreted by humans, and to facilitate data exploration. This framework embraces the vast cell-to-cell variability that is observed within a normal population, facilitates the integration of cell-by-cell structural data and allows quantitative analyses of distinct, separable aspects of organization within and across different cell populations. We found that the integrated intracellular organization of interphase cells was robust to the wide range of variation in cell shape in the population; that the average locations of some structures became polarized in cells at the edges of colonies while maintaining the ‘wiring’ of their interactions with other structures; and that, by contrast, changes in the location of structures during early mitotic reorganization were accompanied by changes in their wiring.</jats:p>",
    "DOI": "10.1038/s41586-022-05563-7",
    "type": "article-journal",
    "page": "345-354",
    "source": "Crossref",
    "title": "Integrated intracellular organization and its variations in human iPS cells",
    "volume": "613",
    "author": [
      {
        "given": "Matheus P.",
        "family": "Viana"
      },
      {
        "given": "Jianxu",
        "family": "Chen"
      },
      {
        "given": "Theo A.",
        "family": "Knijnenburg"
      },
      {
        "given": "Ritvik",
        "family": "Vasan"
      },
      {
        "given": "Calysta",
        "family": "Yan"
      },
      {
        "given": "Joy E.",
        "family": "Arakaki"
      },
      {
        "given": "Matte",
        "family": "Bailey"
      },
      {
        "given": "Ben",
        "family": "Berry"
      },
      {
        "given": "Antoine",
        "family": "Borensztejn"
      },
      {
        "given": "Eva M.",
        "family": "Brown"
      },
      {
        "given": "Sara",
        "family": "Carlson"
      },
      {
        "given": "Julie A.",
        "family": "Cass"
      },
      {
        "given": "Basudev",
        "family": "Chaudhuri"
      },
      {
        "given": "Kimberly R.",
        "family": "Cordes Metzler"
      },
      {
        "given": "Mackenzie E.",
        "family": "Coston"
      },
      {
        "given": "Zach J.",
        "family": "Crabtree"
      },
      {
        "given": "Steve",
        "family": "Davidson"
      },
      {
        "given": "Colette M.",
        "family": "DeLizo"
      },
      {
        "given": "Shailja",
        "family": "Dhaka"
      },
      {
        "given": "Stephanie Q.",
        "family": "Dinh"
      },
      {
        "given": "Thao P.",
        "family": "Do"
      },
      {
        "given": "Justin",
        "family": "Domingus"
      },
      {
        "given": "Rory M.",
        "family": "Donovan-Maiye"
      },
      {
        "given": "Alexandra J.",
        "family": "Ferrante"
      },
      {
        "given": "Tyler J.",
        "family": "Foster"
      },
      {
        "given": "Christopher L.",
        "family": "Frick"
      },
      {
        "given": "Griffin",
        "family": "Fujioka"
      },
      {
        "given": "Margaret A.",
        "family": "Fuqua"
      },
      {
        "given": "Jamie L.",
        "family": "Gehring"
      },
      {
        "given": "Kaytlyn A.",
        "family": "Gerbin"
      },
      {
        "given": "Tanya",
        "family": "Grancharova"
      },
      {
        "given": "Benjamin W.",
        "family": "Gregor"
      },
      {
        "given": "Lisa J.",
        "family": "Harrylock"
      },
      {
        "given": "Amanda",
        "family": "Haupt"
      },
      {
        "given": "Melissa C.",
        "family": "Hendershott"
      },
      {
        "given": "Caroline",
        "family": "Hookway"
      },
      {
        "given": "Alan R.",
        "family": "Horwitz"
      },
      {
        "given": "H. Christopher",
        "family": "Hughes"
      },
      {
        "given": "Eric J.",
        "family": "Isaac"
      },
      {
        "given": "Gregory R.",
        "family": "Johnson"
      },
      {
        "given": "Brian",
        "family": "Kim"
      },
      {
        "given": "Andrew N.",
        "family": "Leonard"
      },
      {
        "given": "Winnie W.",
        "family": "Leung"
      },
      {
        "given": "Jordan J.",
        "family": "Lucas"
      },
      {
        "given": "Susan A.",
        "family": "Ludmann"
      },
      {
        "given": "Blair M.",
        "family": "Lyons"
      },
      {
        "given": "Haseeb",
        "family": "Malik"
      },
      {
        "given": "Ryan",
        "family": "McGregor"
      },
      {
        "given": "Gabe E.",
        "family": "Medrash"
      },
      {
        "given": "Sean L.",
        "family": "Meharry"
      },
      {
        "given": "Kevin",
        "family": "Mitcham"
      },
      {
        "given": "Irina A.",
        "family": "Mueller"
      },
      {
        "given": "Timothy L.",
        "family": "Murphy-Stevens"
      },
      {
        "given": "Aditya",
        "family": "Nath"
      },
      {
        "given": "Angelique M.",
        "family": "Nelson"
      },
      {
        "given": "Sandra A.",
        "family": "Oluoch"
      },
      {
        "given": "Luana",
        "family": "Paleologu"
      },
      {
        "given": "T. Alexander",
        "family": "Popiel"
      },
      {
        "given": "Megan M.",
        "family": "Riel-Mehan"
      },
      {
        "given": "Brock",
        "family": "Roberts"
      },
      {
        "given": "Lisa M.",
        "family": "Schaefbauer"
      },
      {
        "given": "Magdalena",
        "family": "Schwarzl"
      },
      {
        "given": "Jamie",
        "family": "Sherman"
      },
      {
        "given": "Sylvain",
        "family": "Slaton"
      },
      {
        "given": "M. Filip",
        "family": "Sluzewski"
      },
      {
        "given": "Jacqueline E.",
        "family": "Smith"
      },
      {
        "given": "Youngmee",
        "family": "Sul"
      },
      {
        "given": "Madison J.",
        "family": "Swain-Bowden"
      },
      {
        "given": "W. Joyce",
        "family": "Tang"
      },
      {
        "given": "Derek J.",
        "family": "Thirstrup"
      },
      {
        "given": "Daniel M.",
        "family": "Toloudis"
      },
      {
        "given": "Andrew P.",
        "family": "Tucker"
      },
      {
        "given": "Veronica",
        "family": "Valencia"
      },
      {
        "given": "Winfried",
        "family": "Wiegraebe"
      },
      {
        "given": "Thushara",
        "family": "Wijeratna"
      },
      {
        "given": "Ruian",
        "family": "Yang"
      },
      {
        "given": "Rebecca J.",
        "family": "Zaunbrecher"
      },
      {
        "given": "Ramon Lorenzo D.",
        "family": "Labitigan"
      },
      {
        "given": "Adrian L.",
        "family": "Sanborn"
      },
      {
        "given": "Graham T.",
        "family": "Johnson"
      },
      {
        "given": "Ruwanthi N.",
        "family": "Gunawardane"
      },
      {
        "given": "Nathalie",
        "family": "Gaudreault"
      },
      {
        "given": "Julie A.",
        "family": "Theriot"
      },
      {
        "given": "Susanne M.",
        "family": "Rafelski"
      }
    ],
    "container-title": "Nature",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          1,
          4
        ]
      ]
    },
    "URL": "https://doi.org/grkztd",
    "container-title-short": "Nature",
    "PMCID": "PMC9834050",
    "PMID": "36599983",
    "id": "5sGcmDuy",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41586-022-05563-7"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "11",
    "DOI": "10.1038/s41592-018-0111-2",
    "type": "article-journal",
    "page": "917-920",
    "source": "Crossref",
    "title": "Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy",
    "volume": "15",
    "author": [
      {
        "given": "Chawin",
        "family": "Ounkomol"
      },
      {
        "given": "Sharmishtaa",
        "family": "Seshamani"
      },
      {
        "given": "Mary M.",
        "family": "Maleckar"
      },
      {
        "given": "Forrest",
        "family": "Collman"
      },
      {
        "given": "Gregory R.",
        "family": "Johnson"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2018,
          9,
          17
        ]
      ]
    },
    "URL": "https://doi.org/gd7d5f",
    "container-title-short": "Nat Methods",
    "PMCID": "PMC6212323",
    "PMID": "30224672",
    "id": "Yq8wZ6hc",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-018-0111-2"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "12",
    "DOI": "10.1038/s41592-018-0216-7",
    "type": "article-journal",
    "page": "1090-1097",
    "source": "Crossref",
    "title": "Content-aware image restoration: pushing the limits of fluorescence microscopy",
    "volume": "15",
    "author": [
      {
        "given": "Martin",
        "family": "Weigert"
      },
      {
        "given": "Uwe",
        "family": "Schmidt"
      },
      {
        "given": "Tobias",
        "family": "Boothe"
      },
      {
        "given": "Andreas",
        "family": "Müller"
      },
      {
        "given": "Alexandr",
        "family": "Dibrov"
      },
      {
        "given": "Akanksha",
        "family": "Jain"
      },
      {
        "given": "Benjamin",
        "family": "Wilhelm"
      },
      {
        "given": "Deborah",
        "family": "Schmidt"
      },
      {
        "given": "Coleman",
        "family": "Broaddus"
      },
      {
        "given": "Siân",
        "family": "Culley"
      },
      {
        "given": "Mauricio",
        "family": "Rocha-Martins"
      },
      {
        "given": "Fabián",
        "family": "Segovia-Miranda"
      },
      {
        "given": "Caren",
        "family": "Norden"
      },
      {
        "given": "Ricardo",
        "family": "Henriques"
      },
      {
        "given": "Marino",
        "family": "Zerial"
      },
      {
        "given": "Michele",
        "family": "Solimena"
      },
      {
        "given": "Jochen",
        "family": "Rink"
      },
      {
        "given": "Pavel",
        "family": "Tomancak"
      },
      {
        "given": "Loic",
        "family": "Royer"
      },
      {
        "given": "Florian",
        "family": "Jug"
      },
      {
        "given": "Eugene W.",
        "family": "Myers"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2018,
          11,
          26
        ]
      ]
    },
    "URL": "https://doi.org/gfkkfd",
    "container-title-short": "Nat Methods",
    "id": "12G712Zky",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-018-0216-7"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "1",
    "DOI": "10.1038/s41592-020-01018-x",
    "type": "article-journal",
    "page": "100-106",
    "source": "Crossref",
    "title": "Cellpose: a generalist algorithm for cellular segmentation",
    "volume": "18",
    "author": [
      {
        "given": "Carsen",
        "family": "Stringer"
      },
      {
        "given": "Tim",
        "family": "Wang"
      },
      {
        "given": "Michalis",
        "family": "Michaelos"
      },
      {
        "given": "Marius",
        "family": "Pachitariu"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2020,
          12,
          14
        ]
      ]
    },
    "URL": "https://doi.org/ghrgms",
    "container-title-short": "Nat Methods",
    "id": "TugPkOLy",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-020-01018-x"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "4",
    "DOI": "10.1038/s41592-021-01080-z",
    "type": "article-journal",
    "page": "406-416",
    "source": "Crossref",
    "title": "Deep learning-based point-scanning super-resolution imaging",
    "volume": "18",
    "author": [
      {
        "given": "Linjing",
        "family": "Fang"
      },
      {
        "given": "Fred",
        "family": "Monroe"
      },
      {
        "given": "Sammy Weiser",
        "family": "Novak"
      },
      {
        "given": "Lyndsey",
        "family": "Kirk"
      },
      {
        "given": "Cara R.",
        "family": "Schiavon"
      },
      {
        "given": "Seungyoon B.",
        "family": "Yu"
      },
      {
        "given": "Tong",
        "family": "Zhang"
      },
      {
        "given": "Melissa",
        "family": "Wu"
      },
      {
        "given": "Kyle",
        "family": "Kastner"
      },
      {
        "given": "Alaa Abdel",
        "family": "Latif"
      },
      {
        "given": "Zijun",
        "family": "Lin"
      },
      {
        "given": "Andrew",
        "family": "Shaw"
      },
      {
        "given": "Yoshiyuki",
        "family": "Kubota"
      },
      {
        "given": "John",
        "family": "Mendenhall"
      },
      {
        "given": "Zhao",
        "family": "Zhang"
      },
      {
        "given": "Gulcin",
        "family": "Pekkurnaz"
      },
      {
        "given": "Kristen",
        "family": "Harris"
      },
      {
        "given": "Jeremy",
        "family": "Howard"
      },
      {
        "given": "Uri",
        "family": "Manor"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2021,
          3,
          8
        ]
      ]
    },
    "URL": "https://doi.org/gjhgrw",
    "container-title-short": "Nat Methods",
    "PMCID": "PMC8035334",
    "PMID": "33686300",
    "id": "wcCVn8av",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-021-01080-z"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "6",
    "DOI": "10.1038/s41592-021-01155-x",
    "type": "article-journal",
    "page": "678-687",
    "source": "Crossref",
    "title": "Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes",
    "volume": "18",
    "author": [
      {
        "given": "Jiji",
        "family": "Chen"
      },
      {
        "given": "Hideki",
        "family": "Sasaki"
      },
      {
        "given": "Hoyin",
        "family": "Lai"
      },
      {
        "given": "Yijun",
        "family": "Su"
      },
      {
        "given": "Jiamin",
        "family": "Liu"
      },
      {
        "given": "Yicong",
        "family": "Wu"
      },
      {
        "given": "Alexander",
        "family": "Zhovmer"
      },
      {
        "given": "Christian A.",
        "family": "Combs"
      },
      {
        "given": "Ivan",
        "family": "Rey-Suarez"
      },
      {
        "given": "Hung-Yu",
        "family": "Chang"
      },
      {
        "given": "Chi Chou",
        "family": "Huang"
      },
      {
        "given": "Xuesong",
        "family": "Li"
      },
      {
        "given": "Min",
        "family": "Guo"
      },
      {
        "given": "Srineil",
        "family": "Nizambad"
      },
      {
        "given": "Arpita",
        "family": "Upadhyaya"
      },
      {
        "given": "Shih-Jong J.",
        "family": "Lee"
      },
      {
        "given": "Luciano A. G.",
        "family": "Lucas"
      },
      {
        "given": "Hari",
        "family": "Shroff"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          31
        ]
      ]
    },
    "URL": "https://doi.org/gkbctn",
    "container-title-short": "Nat Methods",
    "id": "UEBDZ3tI",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-021-01155-x"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "9",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Light microscopy combined with well-established protocols of two-dimensional cell culture facilitates high-throughput quantitative imaging to study biological phenomena. Accurate segmentation of individual cells in images enables exploration of complex biological questions, but can require sophisticated imaging processing pipelines in cases of low contrast and high object density. Deep learning-based methods are considered state-of-the-art for image segmentation but typically require vast amounts of annotated data, for which there is no suitable resource available in the field of label-free cellular imaging. Here, we present LIVECell, a large, high-quality, manually annotated and expert-validated dataset of phase-contrast images, consisting of over 1.6 million cells from a diverse set of cell morphologies and culture densities. To further demonstrate its use, we train convolutional neural network-based models using LIVECell and evaluate model segmentation accuracy with a proposed a suite of benchmarks.</jats:p>",
    "DOI": "10.1038/s41592-021-01249-6",
    "type": "article-journal",
    "page": "1038-1045",
    "source": "Crossref",
    "title": "LIVECell—A large-scale dataset for label-free live cell segmentation",
    "volume": "18",
    "author": [
      {
        "given": "Christoffer",
        "family": "Edlund"
      },
      {
        "given": "Timothy R.",
        "family": "Jackson"
      },
      {
        "given": "Nabeel",
        "family": "Khalid"
      },
      {
        "given": "Nicola",
        "family": "Bevan"
      },
      {
        "given": "Timothy",
        "family": "Dale"
      },
      {
        "given": "Andreas",
        "family": "Dengel"
      },
      {
        "given": "Sheraz",
        "family": "Ahmed"
      },
      {
        "given": "Johan",
        "family": "Trygg"
      },
      {
        "given": "Rickard",
        "family": "Sjögren"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2021,
          8,
          30
        ]
      ]
    },
    "URL": "https://doi.org/gmptqs",
    "container-title-short": "Nat Methods",
    "PMCID": "PMC8440198",
    "PMID": "34462594",
    "id": "xPgDok51",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-021-01249-6"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "11",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Advances in microscopy hold great promise for allowing quantitative and precise measurement of morphological and molecular phenomena at the single-cell level in bacteria; however, the potential of this approach is ultimately limited by the availability of methods to faithfully segment cells independent of their morphological or optical characteristics. Here, we present Omnipose, a deep neural network image-segmentation algorithm. Unique network outputs such as the gradient of the distance field allow Omnipose to accurately segment cells on which current algorithms, including its predecessor, Cellpose, produce errors. We show that Omnipose achieves unprecedented segmentation performance on mixed bacterial cultures, antibiotic-treated cells and cells of elongated or branched morphology. Furthermore, the benefits of Omnipose extend to non-bacterial subjects, varied imaging modalities and three-dimensional objects. Finally, we demonstrate the utility of Omnipose in the characterization of extreme morphological phenotypes that arise during interbacterial antagonism. Our results distinguish Omnipose as a powerful tool for characterizing diverse and arbitrarily shaped cell types from imaging data.</jats:p>",
    "DOI": "10.1038/s41592-022-01639-4",
    "type": "article-journal",
    "page": "1438-1448",
    "source": "Crossref",
    "title": "Omnipose: a high-precision morphology-independent solution for bacterial cell segmentation",
    "volume": "19",
    "author": [
      {
        "given": "Kevin J.",
        "family": "Cutler"
      },
      {
        "given": "Carsen",
        "family": "Stringer"
      },
      {
        "given": "Teresa W.",
        "family": "Lo"
      },
      {
        "given": "Luca",
        "family": "Rappez"
      },
      {
        "given": "Nicholas",
        "family": "Stroustrup"
      },
      {
        "given": "S.",
        "family": "Brook Peterson"
      },
      {
        "given": "Paul A.",
        "family": "Wiggins"
      },
      {
        "given": "Joseph D.",
        "family": "Mougous"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          10,
          17
        ]
      ]
    },
    "URL": "https://doi.org/grnd95",
    "container-title-short": "Nat Methods",
    "PMCID": "PMC9636021",
    "PMID": "36253643",
    "id": "lXzmjM5n",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-022-01639-4"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "7",
    "DOI": "10.1038/s41592-023-01881-4",
    "type": "article-journal",
    "page": "968-970",
    "source": "Crossref",
    "title": "When seeing is not believing: application-appropriate validation matters for quantitative bioimage analysis",
    "volume": "20",
    "author": [
      {
        "given": "Jianxu",
        "family": "Chen"
      },
      {
        "given": "Matheus P.",
        "family": "Viana"
      },
      {
        "given": "Susanne M.",
        "family": "Rafelski"
      }
    ],
    "container-title": "Nature Methods",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          7
        ]
      ]
    },
    "URL": "https://doi.org/gss3cm",
    "container-title-short": "Nat Methods",
    "id": "C2iqR6xE",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41592-023-01881-4"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "10",
    "DOI": "10.1038/s42256-019-0096-2",
    "type": "article-journal",
    "page": "461-470",
    "source": "Crossref",
    "title": "Unsupervised data to content transformation with histogram-matching cycle-consistent generative adversarial networks",
    "volume": "1",
    "author": [
      {
        "given": "Stephan J.",
        "family": "Ihle"
      },
      {
        "given": "Andreas M.",
        "family": "Reichmuth"
      },
      {
        "given": "Sophie",
        "family": "Girardin"
      },
      {
        "given": "Hana",
        "family": "Han"
      },
      {
        "given": "Flurin",
        "family": "Stauffer"
      },
      {
        "given": "Anne",
        "family": "Bonnin"
      },
      {
        "given": "Marco",
        "family": "Stampanoni"
      },
      {
        "given": "Karthik",
        "family": "Pattisapu"
      },
      {
        "given": "János",
        "family": "Vörös"
      },
      {
        "given": "Csaba",
        "family": "Forró"
      }
    ],
    "container-title": "Nature Machine Intelligence",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2019,
          9,
          16
        ]
      ]
    },
    "URL": "https://doi.org/ggwbcv",
    "container-title-short": "Nat Mach Intell",
    "id": "RuFP3CS3",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s42256-019-0096-2"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "4",
    "DOI": "10.1038/s42256-022-00471-x",
    "type": "article-journal",
    "page": "401-412",
    "source": "Crossref",
    "title": "Deep learning-inferred multiplex immunofluorescence for immunohistochemical image quantification",
    "volume": "4",
    "author": [
      {
        "given": "Parmida",
        "family": "Ghahremani"
      },
      {
        "given": "Yanyun",
        "family": "Li"
      },
      {
        "given": "Arie",
        "family": "Kaufman"
      },
      {
        "given": "Rami",
        "family": "Vanguri"
      },
      {
        "given": "Noah",
        "family": "Greenwald"
      },
      {
        "given": "Michael",
        "family": "Angelo"
      },
      {
        "given": "Travis J.",
        "family": "Hollmann"
      },
      {
        "given": "Saad",
        "family": "Nadeem"
      }
    ],
    "container-title": "Nature Machine Intelligence",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          7
        ]
      ]
    },
    "URL": "https://doi.org/gqc7gd",
    "container-title-short": "Nat Mach Intell",
    "PMCID": "PMC9477216",
    "PMID": "36118303",
    "id": "WwenuBHa",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s42256-022-00471-x"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>A continuing challenge in quantitative cell biology is the accurate and robust 3D segmentation of structures of interest from fluorescence microscopy images in an automated, reproducible, and widely accessible manner for subsequent interpretable data analysis. We describe the Allen Cell and Structure Segmenter (Segmenter), a Python-based open source toolkit developed for 3D segmentation of cells and intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high-replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes. The Segmenter consists of two complementary elements, a classic image segmentation workflow with a restricted set of algorithms and parameters and an iterative deep learning segmentation workflow. We created a collection of 20 classic image segmentation workflows based on 20 distinct and representative intracellular structure localization patterns as a “lookup table” reference and starting point for users. The iterative deep learning workflow can take over when the classic segmentation workflow is insufficient. Two straightforward “human-in-the-loop” curation strategies convert a set of classic image segmentation workflow results into a set of 3D ground truth images for iterative model training without the need for manual painting in 3D. The deep learning model architectures used in this toolkit were designed and tested specifically for 3D fluorescence microscope images and implemented as readable scripts. The Segmenter thus leverages state of the art computer vision algorithms in an accessible way to facilitate their application by the experimental biology researcher.</jats:p><jats:p>We include two useful applications to demonstrate how we used the classic image segmentation and iterative deep learning workflows to solve more challenging 3D segmentation tasks. First, we introduce the ‘Training Assay’ approach, a new experimental-computational co-design concept to generate more biologically accurate segmentation ground truths. We combined the iterative deep learning workflow with three Training Assays to develop a robust, scalable cell and nuclear instance segmentation algorithm, which could achieve accurate target segmentation for over 98% of individual cells and over 80% of entire fields of view. Second, we demonstrate how to extend the lamin B1 segmentation model built from the iterative deep learning workflow to obtain more biologically accurate lamin B1 segmentation by utilizing multi-channel inputs and combining multiple ML models. The steps and workflows used to develop these algorithms are generalizable to other similar segmentation challenges. More information, including tutorials and code repositories, are available at allencell.org/segmenter.</jats:p>",
    "DOI": "10.1101/491035",
    "type": "manuscript",
    "source": "Crossref",
    "title": "The Allen Cell and Structure Segmenter: a new open source toolkit for segmenting 3D intracellular structures in fluorescence microscopy images",
    "author": [
      {
        "given": "Jianxu",
        "family": "Chen"
      },
      {
        "given": "Liya",
        "family": "Ding"
      },
      {
        "given": "Matheus P.",
        "family": "Viana"
      },
      {
        "given": "HyeonWoo",
        "family": "Lee"
      },
      {
        "given": "M. Filip",
        "family": "Sluezwski"
      },
      {
        "given": "Benjamin",
        "family": "Morris"
      },
      {
        "given": "Melissa C.",
        "family": "Hendershott"
      },
      {
        "given": "Ruian",
        "family": "Yang"
      },
      {
        "given": "Irina A.",
        "family": "Mueller"
      },
      {
        "given": "Susanne M.",
        "family": "Rafelski"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2018,
          12,
          8
        ]
      ]
    },
    "URL": "https://doi.org/gkspnm",
    "id": "jM3v1UjQ",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/491035"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/cvpr.2009.5206848",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "ImageNet: A large-scale hierarchical image database",
    "author": [
      {
        "given": "Jia",
        "family": "Deng"
      },
      {
        "given": "Wei",
        "family": "Dong"
      },
      {
        "given": "Richard",
        "family": "Socher"
      },
      {
        "given": "Li-Jia",
        "family": "Li"
      },
      {
        "family": "Kai Li"
      },
      {
        "family": "Li Fei-Fei"
      }
    ],
    "event": "2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops)",
    "container-title": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
    "issued": {
      "date-parts": [
        [
          2009,
          6
        ]
      ]
    },
    "URL": "https://doi.org/cvc7xp",
    "id": "lt4BNUoG",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/cvpr.2009.5206848"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/cvpr.2017.632",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "Image-to-Image Translation with Conditional Adversarial Networks",
    "author": [
      {
        "given": "Phillip",
        "family": "Isola"
      },
      {
        "given": "Jun-Yan",
        "family": "Zhu"
      },
      {
        "given": "Tinghui",
        "family": "Zhou"
      },
      {
        "given": "Alexei A.",
        "family": "Efros"
      }
    ],
    "event": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
    "container-title": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
    "issued": {
      "date-parts": [
        [
          2017,
          7
        ]
      ]
    },
    "URL": "https://doi.org/gfrfv9",
    "id": "LxlUp436",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/cvpr.2017.632"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/cvpr.2019.00963",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "Panoptic Segmentation",
    "author": [
      {
        "given": "Alexander",
        "family": "Kirillov"
      },
      {
        "given": "Kaiming",
        "family": "He"
      },
      {
        "given": "Ross",
        "family": "Girshick"
      },
      {
        "given": "Carsten",
        "family": "Rother"
      },
      {
        "given": "Piotr",
        "family": "Dollar"
      }
    ],
    "event": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
    "container-title": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
    "issued": {
      "date-parts": [
        [
          2019,
          6
        ]
      ]
    },
    "URL": "https://doi.org/ggp9z4",
    "id": "11chATuF4",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/cvpr.2019.00963"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/cvpr42600.2020.00470",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "Fast Symmetric Diffeomorphic Image Registration with Convolutional Neural Networks",
    "author": [
      {
        "given": "Tony C.W.",
        "family": "Mok"
      },
      {
        "given": "Albert C.S.",
        "family": "Chung"
      }
    ],
    "event": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
    "container-title": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
    "issued": {
      "date-parts": [
        [
          2020,
          6
        ]
      ]
    },
    "URL": "https://doi.org/gg99pz",
    "id": "1Fh9QLxl9",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/cvpr42600.2020.00470"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/cvprw.2017.151",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "Enhanced Deep Residual Networks for Single Image Super-Resolution",
    "author": [
      {
        "given": "Bee",
        "family": "Lim"
      },
      {
        "given": "Sanghyun",
        "family": "Son"
      },
      {
        "given": "Heewon",
        "family": "Kim"
      },
      {
        "given": "Seungjun",
        "family": "Nah"
      },
      {
        "given": "Kyoung Mu",
        "family": "Lee"
      }
    ],
    "event": "2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
    "container-title": "2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
    "issued": {
      "date-parts": [
        [
          2017,
          7
        ]
      ]
    },
    "URL": "https://doi.org/gfxhp3",
    "id": "1O0bopKD",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/cvprw.2017.151"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/iccv.2017.244",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks",
    "author": [
      {
        "given": "Jun-Yan",
        "family": "Zhu"
      },
      {
        "given": "Taesung",
        "family": "Park"
      },
      {
        "given": "Phillip",
        "family": "Isola"
      },
      {
        "given": "Alexei A.",
        "family": "Efros"
      }
    ],
    "event": "2017 IEEE International Conference on Computer Vision (ICCV)",
    "container-title": "2017 IEEE International Conference on Computer Vision (ICCV)",
    "issued": {
      "date-parts": [
        [
          2017,
          10
        ]
      ]
    },
    "URL": "https://doi.org/gfhw33",
    "id": "6wtIu4QY",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/iccv.2017.244"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/isbi.2009.5193250",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "A method for normalizing histology slides for quantitative analysis",
    "author": [
      {
        "given": "Marc",
        "family": "Macenko"
      },
      {
        "given": "Marc",
        "family": "Niethammer"
      },
      {
        "given": "J. S.",
        "family": "Marron"
      },
      {
        "given": "David",
        "family": "Borland"
      },
      {
        "given": "John T.",
        "family": "Woosley"
      },
      {
        "family": "Xiaojun Guan"
      },
      {
        "given": "Charles",
        "family": "Schmitt"
      },
      {
        "given": "Nancy E.",
        "family": "Thomas"
      }
    ],
    "event": "2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro (ISBI)",
    "container-title": "2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro",
    "issued": {
      "date-parts": [
        [
          2009,
          6
        ]
      ]
    },
    "URL": "https://doi.org/bmbj4h",
    "id": "tQhnZyjK",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/isbi.2009.5193250"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/isbi48211.2021.9433928",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "Splinedist: Automated Cell Segmentation With Spline Curves",
    "author": [
      {
        "given": "Soham",
        "family": "Mandal"
      },
      {
        "given": "Virginie",
        "family": "Uhlmann"
      }
    ],
    "event": "2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)",
    "container-title": "2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)",
    "issued": {
      "date-parts": [
        [
          2021,
          4,
          13
        ]
      ]
    },
    "URL": "https://doi.org/gqrg94",
    "id": "17Yrl6WGQ",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/isbi48211.2021.9433928"
  },
  {
    "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
    "issue": "1",
    "DOI": "10.1109/tits.2017.2750080",
    "type": "article-journal",
    "page": "263-272",
    "source": "Crossref",
    "title": "ERFNet: Efficient Residual Factorized ConvNet for Real-Time Semantic Segmentation",
    "volume": "19",
    "author": [
      {
        "given": "Eduardo",
        "family": "Romera"
      },
      {
        "given": "Jose M.",
        "family": "Alvarez"
      },
      {
        "given": "Luis M.",
        "family": "Bergasa"
      },
      {
        "given": "Roberto",
        "family": "Arroyo"
      }
    ],
    "container-title": "IEEE Transactions on Intelligent Transportation Systems",
    "issued": {
      "date-parts": [
        [
          2018,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gcs5h7",
    "container-title-short": "IEEE Trans. Intell. Transport. Syst.",
    "id": "XAkgs3Nh",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/tits.2017.2750080"
  },
  {
    "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
    "issue": "11",
    "DOI": "10.1109/tmi.2015.2433900",
    "type": "article-journal",
    "page": "2366-2378",
    "source": "Crossref",
    "title": "A Stochastic Polygons Model for Glandular Structures in Colon Histology Images",
    "volume": "34",
    "author": [
      {
        "given": "Korsuk",
        "family": "Sirinukunwattana"
      },
      {
        "given": "David R. J.",
        "family": "Snead"
      },
      {
        "given": "Nasir M.",
        "family": "Rajpoot"
      }
    ],
    "container-title": "IEEE Transactions on Medical Imaging",
    "issued": {
      "date-parts": [
        [
          2015,
          11
        ]
      ]
    },
    "URL": "https://doi.org/gqrg95",
    "container-title-short": "IEEE Trans. Med. Imaging",
    "id": "45Sirz1X",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/tmi.2015.2433900"
  },
  {
    "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
    "issue": "2",
    "DOI": "10.1109/tpami.2018.2844175",
    "type": "article-journal",
    "page": "386-397",
    "source": "Crossref",
    "title": "Mask R-CNN",
    "volume": "42",
    "author": [
      {
        "given": "Kaiming",
        "family": "He"
      },
      {
        "given": "Georgia",
        "family": "Gkioxari"
      },
      {
        "given": "Piotr",
        "family": "Dollar"
      },
      {
        "given": "Ross",
        "family": "Girshick"
      }
    ],
    "container-title": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "issued": {
      "date-parts": [
        [
          2020,
          2,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gfxfwn",
    "container-title-short": "IEEE Trans. Pattern Anal. Mach. Intell.",
    "id": "xi8wnibR",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/tpami.2018.2844175"
  },
  {
    "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
    "issue": "11",
    "DOI": "10.1109/tpami.2020.2992393",
    "type": "article-journal",
    "page": "4037-4058",
    "source": "Crossref",
    "title": "Self-Supervised Visual Feature Learning With Deep Neural Networks: A Survey",
    "volume": "43",
    "author": [
      {
        "given": "Longlong",
        "family": "Jing"
      },
      {
        "given": "Yingli",
        "family": "Tian"
      }
    ],
    "container-title": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "issued": {
      "date-parts": [
        [
          2021,
          11,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gg8fm7",
    "container-title-short": "IEEE Trans. Pattern Anal. Mach. Intell.",
    "id": "s2RBSHdH",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/tpami.2020.2992393"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/wacv45572.2020.9093435",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "Star-convex Polyhedra for 3D Object Detection and Segmentation in Microscopy",
    "author": [
      {
        "given": "Martin",
        "family": "Weigert"
      },
      {
        "given": "Uwe",
        "family": "Schmidt"
      },
      {
        "given": "Robert",
        "family": "Haase"
      },
      {
        "given": "Ko",
        "family": "Sugawara"
      },
      {
        "given": "Gene",
        "family": "Myers"
      }
    ],
    "event": "2020 IEEE Winter Conference on Applications of Computer Vision (WACV)",
    "container-title": "2020 IEEE Winter Conference on Applications of Computer Vision (WACV)",
    "issued": {
      "date-parts": [
        [
          2020,
          3
        ]
      ]
    },
    "URL": "https://doi.org/gjp4g9",
    "id": "14h90Vfg0",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/wacv45572.2020.9093435"
  },
  {
    "publisher": "IEEE",
    "DOI": "10.1109/wacv51458.2022.00181",
    "type": "paper-conference",
    "source": "Crossref",
    "title": "UNETR: Transformers for 3D Medical Image Segmentation",
    "author": [
      {
        "given": "Ali",
        "family": "Hatamizadeh"
      },
      {
        "given": "Yucheng",
        "family": "Tang"
      },
      {
        "given": "Vishwesh",
        "family": "Nath"
      },
      {
        "given": "Dong",
        "family": "Yang"
      },
      {
        "given": "Andriy",
        "family": "Myronenko"
      },
      {
        "given": "Bennett",
        "family": "Landman"
      },
      {
        "given": "Holger R.",
        "family": "Roth"
      },
      {
        "given": "Daguang",
        "family": "Xu"
      }
    ],
    "event": "2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)",
    "container-title": "2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)",
    "issued": {
      "date-parts": [
        [
          2022,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gqrg96",
    "id": "XCKUntOB",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1109/wacv51458.2022.00181"
  },
  {
    "publisher": "Public Library of Science (PLoS)",
    "issue": "6",
    "DOI": "10.1371/journal.pcbi.1007128",
    "type": "article-journal",
    "page": "e1007128",
    "source": "Crossref",
    "title": "Open collaborative writing with Manubot",
    "volume": "15",
    "author": [
      {
        "given": "Daniel S.",
        "family": "Himmelstein"
      },
      {
        "given": "Vincent",
        "family": "Rubinetti"
      },
      {
        "given": "David R.",
        "family": "Slochower"
      },
      {
        "given": "Dongbo",
        "family": "Hu"
      },
      {
        "given": "Venkat S.",
        "family": "Malladi"
      },
      {
        "given": "Casey S.",
        "family": "Greene"
      },
      {
        "given": "Anthony",
        "family": "Gitter"
      }
    ],
    "container-title": "PLOS Computational Biology",
    "language": "en",
    "editor": [
      {
        "given": "Dina",
        "family": "Schneidman-Duhovny"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2019,
          6,
          24
        ]
      ]
    },
    "URL": "https://doi.org/c7np",
    "container-title-short": "PLoS Comput Biol",
    "PMCID": "PMC6611653",
    "PMID": "31233491",
    "id": "YuJbg3zO",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1371/journal.pcbi.1007128"
  },
  {
    "publisher": "Public Library of Science (PLoS)",
    "issue": "12",
    "abstract": "<jats:p>Fluorescence reconstruction microscopy (FRM) describes a class of techniques where transmitted light images are passed into a convolutional neural network that then outputs predicted epifluorescence images. This approach enables many benefits including reduced phototoxicity, freeing up of fluorescence channels, simplified sample preparation, and the ability to re-process legacy data for new insights. However, FRM can be complex to implement, and current FRM benchmarks are abstractions that are difficult to relate to how valuable or trustworthy a reconstruction is. Here, we relate the conventional benchmarks and demonstrations to practical and familiar cell biology analyses to demonstrate that FRM should be judged in context. We further demonstrate that it performs remarkably well even with lower-magnification microscopy data, as are often collected in screening and high content imaging. Specifically, we present promising results for nuclei, cell-cell junctions, and fine feature reconstruction; provide data-driven experimental design guidelines; and provide researcher-friendly code, complete sample data, and a researcher manual to enable more widespread adoption of FRM.</jats:p>",
    "DOI": "10.1371/journal.pcbi.1008443",
    "type": "article-journal",
    "page": "e1008443",
    "source": "Crossref",
    "title": "Practical fluorescence reconstruction microscopy for large samples and low-magnification imaging",
    "volume": "16",
    "author": [
      {
        "given": "Julienne",
        "family": "LaChance"
      },
      {
        "given": "Daniel J.",
        "family": "Cohen"
      }
    ],
    "container-title": "PLOS Computational Biology",
    "language": "en",
    "editor": [
      {
        "given": "Daniel A.",
        "family": "Beard"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020,
          12,
          23
        ]
      ]
    },
    "URL": "https://doi.org/grxbww",
    "container-title-short": "PLoS Comput Biol",
    "PMCID": "PMC7802935",
    "PMID": "33362219",
    "id": "gPpwGUco",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.1371/journal.pcbi.1008443"
  },
  {
    "type": "article",
    "id": "xl7YzUeX",
    "author": [
      {
        "family": "Sonneck",
        "given": "Justin"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "# MMV Im2Im Transformation [![Build Status](https://github.com/MMV-Lab/mmv_im2im/workflows/Build%20Main/badge.svg)](https://github.com/MMV-Lab/mmv_im2im/actions) A generic python package for deep learning based image-to-image transformation in biomedical applications The main branch will be further developed in order to be able to use the latest state of the art techniques and methods in the future. To reproduce the results of our manuscript, we refer to the branch [paper_version](https://github.com/MMV-Lab/mmv_im2im/tree/paper_version). (We are actively working on the documentation and tutorials. Submit a feature request if there is anything you need.) --- ## Overview The overall package is designed with a generic image-to-image transformation framework, which could be directly used for semantic segmentation, instance segmentation, image restoration, image generation, labelfree prediction, staining transformation, etc.. The implementation takes advantage of the state-of-the-art ML engineering techniques for users to focus on researches without worrying about the engineering details. In our pre-print [arxiv link](https://arxiv.org/abs/2209.02498), we demonstrated the effectiveness of *MMV_Im2Im* in more than ten different biomedical problems/datasets. * For computational biomedical researchers (e.g., AI algorithm development or bioimage analysis workflow development), we hope this package could serve as the starting point for their specific problems, since the image-to-image \"boilerplates\" can be easily extended further development or adapted for users' specific problems. * For experimental biomedical researchers, we hope this work provides a comprehensive view of the image-to-image transformation concept through diversified examples and use cases, so that deep learning based image-to-image transformation could be integrated into the assay development process and permit new biomedical studies that can hardly be done only with traditional experimental methods ## Installation Before starting, we recommend to [create a new conda environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands) or [a virtual environment](https://docs.python.org/3/library/venv.html) with Python 3.9+. Please note that the proper setup of hardware is beyond the scope of this pacakge. This package was tested with GPU/CPU on Linux/Windows and CPU on MacOS. [Special note for MacOS users: Directly pip install in MacOS may need [additional setup of xcode](https://developer.apple.com/forums/thread/673827).] ### Install MONAI To reproduce our results, we need to install MONAI's code version of a specific commit. To do this: ``` git clone https://github.com/Project-MONAI/MONAI.git cd ./MONAI git checkout 37b58fcec48f3ec1f84d7cabe9c7ad08a93882c0 pip install . ``` We will remove this step for the main branch in the future to ensure a simplified installation of our tool. ### Install MMV_Im2Im for basic usage: (For users only using this package, not planning to change any code or make any extension): **Option 1: core functionality only** `pip install mmv_im2im` **Option 2: advanced functionality (core + logger)** `pip install mmv_im2im[advance]` **Option 3: to reproduce paper:** `pip install mmv_im2im[paper]` **Option 4: install everything:** `pip install mmv_im2im[all]` For MacOS users, additional ' ' marks are need when using installation tags in zsh. For example, `pip install mmv_im2im[paper]` should be `pip install mmv_im2im'[paper]'` in MacOS. ### Install MMV_Im2Im for customization or extension: ``` git clone https://github.com/MMV-Lab/mmv_im2im.git cd mmv_im2im pip install -e .[all] ``` Note: The `-e` option is the so-called \"editable\" mode. This will allow code changes taking effect immediately. The installation tags, `advance`, `paper`, `all`, are be selected based on your needs. ### (Optional) Install using Docker It is also possible to use our package through [docker](https://www.docker.com/). The installation tutorial is [here](docker/tutorial.md). ### (Optional) Use MMV_Im2Im with Google Colab We provide a web-based demo, if cloud computing is preferred. you can [![Open a 2D labelfree DEMO in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MMV-Lab/mmv_im2im/blob/main/tutorials/colab/labelfree_2d.ipynb). The same demo can de adapted for different applications. ## Quick start You can try out on a simple example following [the quick start guide](tutorials/quick_start.md) Basically, you can specify your training configuration in a yaml file and run training with `run_im2im --config /path/to/train_config.yaml`. Then, you can specify the inference configuration in another yaml file and run inference with `run_im2im --config /path/to/inference_config.yaml`. You can also run the inference as a function with the provided API. This will be useful if you want to run the inference within another python script or workflow. Here is an example: ``` from pathlib import Path from aicsimageio import AICSImage from aicsimageio.writers import OmeTiffWriter from mmv_im2im.configs.config_base import ProgramConfig, parse_adaptor, configuration_validation from mmv_im2im import ProjectTester # load the inference configuration cfg = parse_adaptor(config_class=ProgramConfig, config=\"./paper_configs/semantic_seg_2d_inference.yaml\") cfg = configuration_validation(cfg) # define the executor for inference executor = ProjectTester(cfg) executor.setup_model() executor.setup_data_processing() # get the data, run inference, and save the result fn = Path(\"./data/img_00_IM.tiff\") img = AICSImage(fn).get_image_data(\"YX\", Z=0, C=0, T=0) # or using delayed loading if the data is large # img = AICSImage(fn).get_image_dask_data(\"YX\", Z=0, C=0, T=0) seg = executor.process_one_image(img) OmeTiffWriter.save(seg, \"output.tiff\", dim_orders=\"YX\") ``` ## Tutorials, examples, demonstrations and documentations The overall package aims to achieve both simplicty and flexibilty with the modularized image-to-image boilerplates. To help different users to best use this package, we provide documentations from four different aspects: * [Examples (i.e., scripts and config files)](tutorials/example_by_use_case.md) for reproducing all the experiments in our [pre-print](https://arxiv.org/abs/2209.02498) * A bottom-up tutorials on [how to understand the modularized image-to-image boilerplates](tutorials/how_to_understand_boilerplates.md) (for extending or adapting the package) and [how to understand the configuration system in details](tutorials/how_to_understand_config.md) (for advance usage to make specific customization). * A top-down tutorials as [FAQ](tutorials/FAQ.md), which will continuously grow as we receive more questions. * All the models used in the manuscript and sample data can be found here: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10034416.svg)](https://doi.org/10.5281/zenodo.10034416) ### Contribute models to [BioImage Model Zoo](https://bioimage.io/#/) We highly appreciate the BioImage Model Zoo's initiative to provide a comprehensive collection of pre-trained models for a wide range of applications. To make MMV_Im2Im trained models available as well, the first step involves extracting the state_dict from the PyTorch Lightning checkpoint. This can be done via: ```python import torch ckpt_path = \"./lightning_logs/version_0/checkpoints/last.ckpt\" checkpoint = torch.load(ckpt_path, map_location=torch.device('cpu')) state_dict = checkpoint['state_dict'] torch.save(state_dict, \"./state_dict.pt\") ``` All further steps to provide models can be found in the [official documentation](https://bioimage.io/docs/#/contribute_models/README). ## Development See [CONTRIBUTING.md](CONTRIBUTING.md) for information related to developing the code. **MIT license**",
    "DOI": "10.48546/workflowhub.workflow.626.1",
    "publisher": "WorkflowHub",
    "title": "MMV_Im2Im",
    "URL": "https://doi.org/gs9p8r",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.48546/workflowhub.workflow.626.1"
  },
  {
    "type": "article",
    "id": "1A3yurr7m",
    "categories": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences",
      "68-06"
    ],
    "author": [
      {
        "family": "Waibel",
        "given": "Dominik J. E."
      },
      {
        "family": "Röell",
        "given": "Ernst"
      },
      {
        "family": "Rieck",
        "given": "Bastian"
      },
      {
        "family": "Giryes",
        "given": "Raja"
      },
      {
        "family": "Marr",
        "given": "Carsten"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "Diffusion models are a special type of generative model, capable of synthesising new data from a learnt distribution. We introduce DISPR, a diffusion-based model for solving the inverse problem of three-dimensional (3D) cell shape prediction from two-dimensional (2D) single cell microscopy images. Using the 2D microscopy image as a prior, DISPR is conditioned to predict realistic 3D shape reconstructions. To showcase the applicability of DISPR as a data augmentation tool in a feature-based single cell classification task, we extract morphological features from the red blood cells grouped into six highly imbalanced classes. Adding features from the DISPR predictions to the three minority classes improved the macro F1 score from $F1_\\text{macro} = 55.2 \\pm 4.6\\%$ to $F1_\\text{macro} = 72.2 \\pm 4.9\\%$. We thus demonstrate that diffusion models can be successfully applied to inverse biomedical problems, and that they learn to reconstruct 3D shapes with realistic morphological features from 2D microscopy images.",
    "DOI": "10.48550/arxiv.2208.14125",
    "publisher": "arXiv",
    "title": "A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images",
    "URL": "https://doi.org/gqrthn",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2208.14125"
  },
  {
    "type": "article",
    "id": "EOO2mf0p",
    "categories": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Reinke",
        "given": "Annika"
      },
      {
        "family": "Tizabi",
        "given": "Minu D."
      },
      {
        "family": "Baumgartner",
        "given": "Michael"
      },
      {
        "family": "Eisenmann",
        "given": "Matthias"
      },
      {
        "family": "Heckmann-Nötzel",
        "given": "Doreen"
      },
      {
        "family": "Kavur",
        "given": "A. Emre"
      },
      {
        "family": "Rädsch",
        "given": "Tim"
      },
      {
        "family": "Sudre",
        "given": "Carole H."
      },
      {
        "family": "Acion",
        "given": "Laura"
      },
      {
        "family": "Antonelli",
        "given": "Michela"
      },
      {
        "family": "Arbel",
        "given": "Tal"
      },
      {
        "family": "Bakas",
        "given": "Spyridon"
      },
      {
        "family": "Benis",
        "given": "Arriel"
      },
      {
        "family": "Blaschko",
        "given": "Matthew"
      },
      {
        "family": "Buettner",
        "given": "Florian"
      },
      {
        "family": "Cardoso",
        "given": "M. Jorge"
      },
      {
        "family": "Cheplygina",
        "given": "Veronika"
      },
      {
        "family": "Chen",
        "given": "Jianxu"
      },
      {
        "family": "Christodoulou",
        "given": "Evangelia"
      },
      {
        "family": "Cimini",
        "given": "Beth A."
      },
      {
        "family": "Collins",
        "given": "Gary S."
      },
      {
        "family": "Farahani",
        "given": "Keyvan"
      },
      {
        "family": "Ferrer",
        "given": "Luciana"
      },
      {
        "family": "Galdran",
        "given": "Adrian"
      },
      {
        "family": "van Ginneken",
        "given": "Bram"
      },
      {
        "family": "Glocker",
        "given": "Ben"
      },
      {
        "family": "Godau",
        "given": "Patrick"
      },
      {
        "family": "Haase",
        "given": "Robert"
      },
      {
        "family": "Hashimoto",
        "given": "Daniel A."
      },
      {
        "family": "Hoffman",
        "given": "Michael M."
      },
      {
        "family": "Huisman",
        "given": "Merel"
      },
      {
        "family": "Isensee",
        "given": "Fabian"
      },
      {
        "family": "Jannin",
        "given": "Pierre"
      },
      {
        "family": "Kahn",
        "given": "Charles E."
      },
      {
        "family": "Kainmueller",
        "given": "Dagmar"
      },
      {
        "family": "Kainz",
        "given": "Bernhard"
      },
      {
        "family": "Karargyris",
        "given": "Alexandros"
      },
      {
        "family": "Karthikesalingam",
        "given": "Alan"
      },
      {
        "family": "Kenngott",
        "given": "Hannes"
      },
      {
        "family": "Kleesiek",
        "given": "Jens"
      },
      {
        "family": "Kofler",
        "given": "Florian"
      },
      {
        "family": "Kooi",
        "given": "Thijs"
      },
      {
        "family": "Kopp-Schneider",
        "given": "Annette"
      },
      {
        "family": "Kozubek",
        "given": "Michal"
      },
      {
        "family": "Kreshuk",
        "given": "Anna"
      },
      {
        "family": "Kurc",
        "given": "Tahsin"
      },
      {
        "family": "Landman",
        "given": "Bennett A."
      },
      {
        "family": "Litjens",
        "given": "Geert"
      },
      {
        "family": "Madani",
        "given": "Amin"
      },
      {
        "family": "Maier-Hein",
        "given": "Klaus"
      },
      {
        "family": "Martel",
        "given": "Anne L."
      },
      {
        "family": "Mattson",
        "given": "Peter"
      },
      {
        "family": "Meijering",
        "given": "Erik"
      },
      {
        "family": "Menze",
        "given": "Bjoern"
      },
      {
        "family": "Moons",
        "given": "Karel G. M."
      },
      {
        "family": "Müller",
        "given": "Henning"
      },
      {
        "family": "Nichyporuk",
        "given": "Brennan"
      },
      {
        "family": "Nickel",
        "given": "Felix"
      },
      {
        "family": "Petersen",
        "given": "Jens"
      },
      {
        "family": "Rafelski",
        "given": "Susanne M."
      },
      {
        "family": "Rajpoot",
        "given": "Nasir"
      },
      {
        "family": "Reyes",
        "given": "Mauricio"
      },
      {
        "family": "Riegler",
        "given": "Michael A."
      },
      {
        "family": "Rieke",
        "given": "Nicola"
      },
      {
        "family": "Saez-Rodriguez",
        "given": "Julio"
      },
      {
        "family": "Sánchez",
        "given": "Clara I."
      },
      {
        "family": "Shetty",
        "given": "Shravya"
      },
      {
        "family": "van Smeden",
        "given": "Maarten"
      },
      {
        "family": "Summers",
        "given": "Ronald M."
      },
      {
        "family": "Taha",
        "given": "Abdel A."
      },
      {
        "family": "Tiulpin",
        "given": "Aleksei"
      },
      {
        "family": "Tsaftaris",
        "given": "Sotirios A."
      },
      {
        "family": "Van Calster",
        "given": "Ben"
      },
      {
        "family": "Varoquaux",
        "given": "Gaël"
      },
      {
        "family": "Wiesenfarth",
        "given": "Manuel"
      },
      {
        "family": "Yaniv",
        "given": "Ziv R."
      },
      {
        "family": "Jäger",
        "given": "Paul F."
      },
      {
        "family": "Maier-Hein",
        "given": "Lena"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Validation metrics are key for the reliable tracking of scientific progress and for bridging the current chasm between artificial intelligence (AI) research and its translation into practice. However, increasing evidence shows that particularly in image analysis, metrics are often chosen inadequately in relation to the underlying research problem. This could be attributed to a lack of accessibility of metric-related knowledge: While taking into account the individual strengths, weaknesses, and limitations of validation metrics is a critical prerequisite to making educated choices, the relevant knowledge is currently scattered and poorly accessible to individual researchers. Based on a multi-stage Delphi process conducted by a multidisciplinary expert consortium as well as extensive community feedback, the present work provides the first reliable and comprehensive common point of access to information on pitfalls related to validation metrics in image analysis. Focusing on biomedical image analysis but with the potential of transfer to other fields, the addressed pitfalls generalize across application domains and are categorized according to a newly created, domain-agnostic taxonomy. To facilitate comprehension, illustrations and specific examples accompany each pitfall. As a structured body of information accessible to researchers of all levels of expertise, this work enhances global comprehension of a key topic in image analysis validation.",
    "DOI": "10.48550/arxiv.2302.01790",
    "publisher": "arXiv",
    "title": "Understanding metric-related pitfalls in image analysis validation",
    "URL": "https://doi.org/grxbwx",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2302.01790"
  },
  {
    "type": "dataset",
    "id": "FBoj3fXM",
    "author": [
      {
        "family": "Sonneck",
        "given": "Justin"
      },
      {
        "family": "Zhou",
        "given": "Yu"
      },
      {
        "family": "Chen",
        "given": "Jianxu"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          10,
          24
        ]
      ]
    },
    "abstract": "This dataset contains trained deep learning models and sample data for the manuscript \"MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation\". Please find the software and more information including tutorials here: https://github.com/MMV-Lab/mmv_im2im.\n \nsample_data.zip includes the following datasets:\n\nLabelfree prediction of nuclear structure from 2D/3D brighteld images\n\n2D\n\nhttps://zenodo.org/record/6139958#.Y78QJKrMLtU\nhttps://zenodo.org/record/6140064#.Y78YeqrMLtU\nBoth repositories have a Creative Commons Attribution 4.0 International License\n3D\n\nhttps://open.quiltdata.com/b/allencell/packages/aics/hipsc_single_cell_image_dataset\nTerms of use: https://www.allencell.org/terms-of-use.html\n\"Your use of the Content, including creation of derivative works of the services, data and tools, must be for research or other noncommercial purposes unless it is otherwise set forth in these Terms or agreed to in writing by the Allen Institute.\"\n2D semantic segmentation of tissues from H&E images\n\nhttps://www.kaggle.com/datasets/sani84/glasmiccai2015-gland-segmentation\n\"The dataset used in this competition is provided for research purposes only. Commercial uses are not allowed.If you intend to publish research work that uses this dataset, you must cite our review paper to be published after the competition\"\nInstance segmentation\n\n2D\n\nhttps://bbbc.broadinstitute.org/BBBC010\nTerms of use: https://bbbc.broadinstitute.org/\n\"Researchers are encouraged to use these image sets as reference points when developing, testing, and publishing new image analysis algorithms for the life sciences.\"\n3D\n\nhttps://open.quiltdata.com/b/allencell/packages/aics/hipsc_single_cell_image_dataset\nTerms of use: https://www.allencell.org/terms-of-use.html\n\"Your use of the Content, including creation of derivative works of the services, data and tools, must be for research or other noncommercial purposes unless it is otherwise set forth in these Terms or agreed to in writing by the Allen Institute.\"\nCompare semantic segmentation and instance segmentation\n\nhttps://open.quiltdata.com/b/allencell/packages/aics/hipsc_single_cell_image_dataset\nTerms of use: https://www.allencell.org/terms-of-use.html\n\"Your use of the Content, including creation of derivative works of the services, data and tools, must be for research or other noncommercial purposes unless it is otherwise set forth in these Terms or agreed to in writing by the Allen Institute.\"\nUnsupervised semantic segmentation\n\nhttps://open.quiltdata.com/b/allencell/packages/aics/hipsc_single_cell_image_dataset\nTerms of use: https://www.allencell.org/terms-of-use.html\n\"Your use of the Content, including creation of derivative works of the services, data and tools, must be for research or other noncommercial purposes unless it is otherwise set forth in these Terms or agreed to in writing by the Allen Institute.\"\nGenerating synthetic images\n\nhttps://open.quiltdata.com/b/allencell/packages/aics/hipsc_single_cell_image_dataset\nTerms of use: https://www.allencell.org/terms-of-use.html\n\"Your use of the Content, including creation of derivative works of the services, data and tools, must be for research or other noncommercial purposes unless it is otherwise set forth in these Terms or agreed to in writing by the Allen Institute.\"\nImage denoising\n\nhttps://csbdeep.bioimagecomputing.com/scenarios/\nTwo datasets: \"Denoising in 3D (Planaria nuclei)\" and \"Denoising in 3D (Tribolium nuclei)\"\nTerms of use: http://csbdeep.bioimagecomputing.com/\n\"The entire CSBDeep toolbox is fully open source and intended to be used from either Python or Fiji.\"\nImaging modality transformation\n\nhttps://zenodo.org/record/4624364#.Y9bWOoHMIqJ\nTwo datasets: \"Confocal_2_STED.zip\" (Microtubule and Nuclear_Pore_complex)\nRepository has a Creative Commons Attribution 4.0 International License\nStaining transformation:\n\nhttps://zenodo.org/record/4751737#.Y9gbv4HMLVZ\nDataset \"BC-DeepLIIF_Training_Set.zip\" and \"BC-DeepLIIF_Validation_Set.zip\"\nRepository has a Creative Commons Attribution 4.0 International License\n ",
    "DOI": "10.5281/zenodo.10034416",
    "publisher": "Zenodo",
    "title": "MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation",
    "URL": "https://doi.org/gs8p4r",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.5281/zenodo.10034416"
  },
  {
    "type": "book",
    "id": "YEMgt2T4",
    "author": [
      {
        "family": "Ahlers",
        "given": "Jannis"
      },
      {
        "family": "Althviz Moré",
        "given": "Daniel"
      },
      {
        "family": "Amsalem",
        "given": "Oren"
      },
      {
        "family": "Anderson",
        "given": "Ashley"
      },
      {
        "family": "Bokota",
        "given": "Grzegorz"
      },
      {
        "family": "Boone",
        "given": "Peter"
      },
      {
        "family": "Bragantini",
        "given": "Jordão"
      },
      {
        "family": "Buckley",
        "given": "Genevieve"
      },
      {
        "family": "Burt",
        "given": "Alister"
      },
      {
        "family": "Bussonnier",
        "given": "Matthias"
      },
      {
        "family": "Can Solak",
        "given": "Ahmet"
      },
      {
        "family": "Caporal",
        "given": "Clément"
      },
      {
        "family": "Doncila Pop",
        "given": "Draga"
      },
      {
        "family": "Evans",
        "given": "Kira"
      },
      {
        "family": "Freeman",
        "given": "Jeremy"
      },
      {
        "family": "Gaifas",
        "given": "Lorenzo"
      },
      {
        "family": "Gohlke",
        "given": "Christoph"
      },
      {
        "family": "Gunalan",
        "given": "Kabilar"
      },
      {
        "family": "Har-Gil",
        "given": "Hagai"
      },
      {
        "family": "Harfouche",
        "given": "Mark"
      },
      {
        "family": "Harrington",
        "given": "Kyle I. S."
      },
      {
        "family": "Hilsenstein",
        "given": "Volker"
      },
      {
        "family": "Hutchings",
        "given": "Katherine"
      },
      {
        "family": "Lambert",
        "given": "Talley"
      },
      {
        "family": "Lauer",
        "given": "Jessy"
      },
      {
        "family": "Lichtner",
        "given": "Gregor"
      },
      {
        "family": "Liu",
        "given": "Ziyang"
      },
      {
        "family": "Liu",
        "given": "Lucy"
      },
      {
        "family": "Lowe",
        "given": "Alan"
      },
      {
        "family": "Marconato",
        "given": "Luca"
      },
      {
        "family": "Martin",
        "given": "Sean"
      },
      {
        "family": "McGovern",
        "given": "Abigail"
      },
      {
        "family": "Migas",
        "given": "Lukasz"
      },
      {
        "family": "Miller",
        "given": "Nadalyn"
      },
      {
        "family": "Muñoz",
        "given": "Hector"
      },
      {
        "family": "Müller",
        "given": "Jan-Hendrik"
      },
      {
        "family": "Nauroth-Kreß",
        "given": "Christopher"
      },
      {
        "family": "Nunez-Iglesias",
        "given": "Juan"
      },
      {
        "family": "Pape",
        "given": "Constantin"
      },
      {
        "family": "Pevey",
        "given": "Kim"
      },
      {
        "family": "Peña-Castellanos",
        "given": "Gonzalo"
      },
      {
        "family": "Pierré",
        "given": "Andrea"
      },
      {
        "family": "Rodríguez-Guerra",
        "given": "Jaime"
      },
      {
        "family": "Ross",
        "given": "David"
      },
      {
        "family": "Royer",
        "given": "Loic"
      },
      {
        "family": "Russell",
        "given": "Craig T."
      },
      {
        "family": "Selzer",
        "given": "Gabriel"
      },
      {
        "family": "Smith",
        "given": "Paul"
      },
      {
        "family": "Sobolewski",
        "given": "Peter"
      },
      {
        "family": "Sofiiuk",
        "given": "Konstantin"
      },
      {
        "family": "Sofroniew",
        "given": "Nicholas"
      },
      {
        "family": "Stansby",
        "given": "David"
      },
      {
        "family": "Sweet",
        "given": "Andrew"
      },
      {
        "family": "Vierdag",
        "given": "Wouter-Michiel"
      },
      {
        "family": "Wadhwa",
        "given": "Pam"
      },
      {
        "family": "Weber Mendonça",
        "given": "Melissa"
      },
      {
        "family": "Windhager",
        "given": "Jonas"
      },
      {
        "family": "Winston",
        "given": "Philip"
      },
      {
        "family": "Yamauchi",
        "given": "Kevin"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          7,
          5
        ]
      ]
    },
    "abstract": "napari 0.4.18 We're happy to announce the release of napari 0.4.18! napari is a fast, interactive, multi-dimensional image viewer for Python. It's designed for browsing, annotating, and analyzing large multi-dimensional images. It's built on top of Qt (for the GUI), vispy (for performant GPU-based rendering), and the scientific Python stack (numpy, scipy). This is primarily a bug-fix release, addressing many issues from 0.4.17 (see \"Bug Fixes\", below). However, it also contains some performance improvements and several exciting new features (see \"Highlights\"), so read on below! For more information, examples, and documentation, please visit our website: https://napari.org Highlights Drawing polygons in the Shapes layer can now be done much faster with the new lasso tool (napari/napari/#5555) Surface layers now support textures and vertex colors, allowing a whole new type of dataset to be visualised in napari. Have a look at <code>surface_multi_texture.py</code> and <code>surface_texture_and_colors.py</code> in the <code>examples</code> directory for some pretty demos! (napari/napari/#5642) Previously, navigating an image required switching out of whatever drawing mode you might have been using and going back to pan/zoom mode. Now you can use the mouse wheel to zoom in and out in any mode. (napari/napari/#5701) Painting labels is now much, much faster (achieving 60fps even on an 8k x 8k image) (napari/napari/#5723 and napari/napari/#5732) Vectors layers can now be displayed with two different styles of arrowheads, instead of just plain lines. This removes a longstanding limitation of the vectors layer! (napari/napari/#5740) New Features Overlays 2.0 (napari/napari/#4894) expose custom image interpolation kernels (napari/napari/#5130) Add user agent environment variable for pip installations (napari/napari/#5135) Add option to check if plugin try to set viewer attr outside main thread (napari/napari/#5195) Set selection color for QListView item. (napari/napari/#5202) Add warning about set private attr when using proxy (napari/napari/#5209) Shapes interpolation (napari/napari/#5334) Add dask settings to preferences (napari/napari/#5490) Add lasso tool for faster drawing of polygonal Shapes (napari/napari/#5555) Feature: support for textures and vertex colors on Surface layers (napari/napari/#5642) Back point selection with a psygnal Selection (napari/napari/#5691) Zooming with the mouse wheel in any mode (napari/napari/#5701) Add cancellation functionality to progress (napari/napari/#5728) Add arrow display styles to Vectors layer (napari/napari/#5740) Improvements Set keyboard focus on console when opened (napari/napari/#5208) Push variables to console when instantiated (napari/napari/#5210) Tracks layer creation performance improvement (napari/napari/#5303) PERF: Event emissions and perf regression. (napari/napari/#5307) Much faster FormatStringEncoding (napari/napari/#5315) Add parent when creating layer context menu to inherit application theme and add style entry for disabled widgets and menus (napari/napari/#5381) Add correct <code>enablement</code> kwarg to <code>Split Stack</code> action, <code>Convert data type</code> submenu and <code>Projections</code> submenu (napari/napari/#5437) Apply disabled widgets style only for menus and set menus styles for <code>QModelMenu</code> and <code>QMenu</code> instances (napari/napari/#5446) Add disabled style rule for <code>QComboBox</code> following the one for <code>QPushButton</code> (napari/napari/#5469) Allow layers control section to resize to contents (napari/napari/#5474) Allow to use <code>Optional</code> annotation in function return type for magicgui functions (napari/napari/#5595) Skip equality comparisons in EventedModel when unnecessary (napari/napari/#5615) Bugfix: improve layout of Preferences &gt; Shortcuts tables (napari/napari/#5679) Improve preferences genration (napari/napari/#5696) Add dev example for adding custom overlays. (napari/napari/#5719) Disable buffer swapping (napari/napari/#5741) Remove max brush size from increase brush size keybinding (napari/napari/#5761) Explicitly list valid layer names in types (napari/napari/#5823) Sort npe1 widget contributions (napari/napari/#5865) feat: add <code>since_version</code> argument of <code>rename_argument</code> decorator (napari/napari/#5910) Emit extra information with layer.events.data (napari/napari/#5967) Performance Return early when no slicing needed (napari/napari/#5239) Tracks layer creation performance improvement (napari/napari/#5303) PERF: Event emissions and perf regression. (napari/napari/#5307) Much faster FormatStringEncoding (napari/napari/#5315) Fix inefficient label mapping in direct color mode (10-20x speedup) (napari/napari/#5723) Efficient labels mapping for drawing in Labels (60 FPS even with 8000x8000 images) (napari/napari/#5732) Disable buffer swapping (napari/napari/#5741) Bug Fixes Warn instead of failing on empty or invalid alt-text (napari/napari/#4505) Fix display of order and scale combinations (napari/napari/#5004) Enforce that contrast limits must be increasing (napari/napari/#5036) Bugfix: Move Window menu to be before Help (napari/napari/#5093) Add extra garbage collection for some viewer tests (napari/napari/#5108) Connect image to plane events and expose them (napari/napari/#5131) Workaround for discover themes from plugins (napari/napari/#5150) Add missed dialogs to <code>qtbot</code> in <code>test_qt_notifications</code> to prevent segfaults (napari/napari/#5171) DOC Update docstring of <code>add_dock_widget</code> &amp; <code>_add_viewer_dock_widget</code> (napari/napari/#5173) Fix unsortable features (napari/napari/#5186) Avoid possible divide-by-zero in Vectors layer thumbnail update (napari/napari/#5192) Disable napari-console button when launched from jupyter (napari/napari/#5213) Volume rendering updates for isosurface and attenuated MIP (napari/napari/#5215) Return early when no slicing needed (napari/napari/#5239) Check strictly increasing values when clipping contrast limits to a new range (napari/napari/#5258) UI Bugfix: Make disabled QPushButton more distinct (napari/napari/#5262) Respect background color when calculating scale bar color (napari/napari/#5270) Fix circular import in _vispy module (napari/napari/#5276) Use only data dimensions for cord in status bar (napari/napari/#5283) Prevent obsolete reports about failure of cleaning viewer instances (napari/napari/#5317) Add scikit-image[data] to install_requires, because it's required by builtins (napari/napari/#5329) Fix repeating close dialog on macOS and qt 5.12 (napari/napari/#5337) Disable napari-console if napari launched from vanilla python REPL (napari/napari/#5350) For npe2 plugin, use manifest display_name for File &gt; Open Samples (napari/napari/#5351) Bugfix plugin display_name use (File &gt; Open Sample, Plugin menus) (napari/napari/#5366) Fix editing shape data above 2 dimensions (napari/napari/#5383) Fix test keybinding for layer actions (napari/napari/#5406) fix theme id not being used correctly (napari/napari/#5412) Clarify layer's editable property and separate interaction with visible property (napari/napari/#5413) Fix theme reference to get image for <code>success_label</code> style (napari/napari/#5447) Bugfix: Ensure layer._fixed_vertex is set when rotating (napari/napari/#5449) Fix <code>_n_selected_points</code> in _layerlist_context.py (napari/napari/#5450) Refactor Main Window status bar to improve information presentation (napari/napari/#5451) Bugfix: Fix test_get_system_theme test for <code>name</code> to <code>id</code> change (napari/napari/#5456) Bugfix: POLL_INTERVAL_MS used in QTimer needs to be an int on python 3.10 (napari/napari/#5467) Bugfix: Add missing Enums and Flags required by PySide6 &gt; 6.4 (napari/napari/#5480) BugFix: napari does not start with Python v3.11.1: \"ValueError: A distribution name is required.\" (napari/napari/#5482) Fix inverted LUT and blending (napari/napari/#5487) Fix opening file dialogs in PySide (napari/napari/#5492) Handle case when QtDims play thread is partially deleted (napari/napari/#5499) Ensure surface normals and wireframes are using Models internally (napari/napari/#5501) Recursively check for dependent property to fire events. (napari/napari/#5528) Set PYTHONEXECUTABLE as part of macos fixes on (re)startup (napari/napari/#5531) Un-set unified title and tool bar on mac (Qt property) (napari/napari/#5533) Fix key error issue of action manager (napari/napari/#5539) Bugfix: ensure Checkbox state comparisons are correct by using Qt.CheckState(state) (napari/napari/#5541) Clean dangling widget in test (napari/napari/#5544) Fix <code>test_worker_with_progress</code> by wait on worker end (napari/napari/#5548) Fix min req (napari/napari/#5560) Fix vispy axes labels (napari/napari/#5565) Fix colormap utils error suggestion code and add a test (napari/napari/#5571) Fix problem of missing plugin widgets after minimize napari (napari/napari/#5577) Make point size isotropic (napari/napari/#5582) Fix guard of qt import in <code>napari.utils.theme</code> (napari/napari/#5593) Fix empty shapes layer duplication and <code>Convert to Labels</code> enablement logic for selected empty shapes layers (napari/napari/#5594) Stop using removed multichannel= kwarg to skimage functions (napari/napari/#5596) Add information about <code>syntax_style</code> value in error message for theme validation (napari/napari/#5602) Remove catch_warnings in slicing (napari/napari/#5603) Incorret theme should not prevent napari from start (napari/napari/#5605) Unblock axis labels event to be emitted when slider label changes (napari/napari/#5631) Bugfix: IndexError slicing Surface with higher-dimensional vertex_values (napari/napari/#5635) Bugfix: Convert Viewer Delete button to QtViewerPushButton with action and shortcut (napari/napari/#5636) Change dim <code>axis_label</code> resize logic to set width using only displayed labels width (napari/napari/#5640) Feature: support for textures and vertex colors on Surface layers (napari/napari/#5642) Fix features issues with init param and property setter (napari/napari/#5646) Bugfix: Don't double toggle visibility for linked layers (napari/napari/#5656) Bugfix: ensure pan/zoom buttons work, along with spacebar keybinding (napari/napari/#5669) Bugfix: Add Tracks to qt_keyboard_settings (napari/napari/#5678) Fix automatic naming and GUI exposure of multiple unnamed colormaps (napari/napari/#5682) Fix mouse movement handling for <code>TransformBoxOverlay</code> (napari/napari/#5692) Update environment.yml (napari/napari/#5693) Resolve symlinks from path to environment for setting path (napari/napari/#5704) Fix tracks color-by when properties change (napari/napari/#5708) Fix Sphinx warnings (napari/napari/#5717) Do not use depth for canvas overlays; allow setting blending mode for overlays (napari/napari/#5720) Unify event behaviour for points and its qt controls (napari/napari/#5722) Fix camera 3D absolute rotation bug (napari/napari/#5726) Maint: Bump mypy (napari/napari/#5727) Style <code>QGroupBox</code> indicator (napari/napari/#5729) Fix centering of non-displayed dimensions (napari/napari/#5736) Don't attempt to use npe1 readers in napari.plugins._npe2.read (napari/napari/#5739) Prevent canvas micro-panning on point add (",
    "DOI": "10.5281/zenodo.3555620",
    "publisher": "Zenodo",
    "title": "napari: a multi-dimensional image viewer for Python",
    "URL": "https://doi.org/gjpsxz",
    "version": "v0.4.18",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.5281/zenodo.3555620"
  },
  {
    "type": "book",
    "id": "YbvSvdyB",
    "author": [
      {
        "family": "Falcon",
        "given": "William"
      },
      {
        "family": "Borovec",
        "given": "Jirka"
      },
      {
        "family": "Wälchli",
        "given": "Adrian"
      },
      {
        "family": "Eggert",
        "given": "Nic"
      },
      {
        "family": "Schock",
        "given": "Justus"
      },
      {
        "family": "Jordan",
        "given": "Jeremy"
      },
      {
        "family": "Skafte",
        "given": "Nicki"
      },
      {
        "literal": "Ir1dXD"
      },
      {
        "family": "Bereznyuk",
        "given": "Vadim"
      },
      {
        "family": "Harris",
        "given": "Ethan"
      },
      {
        "literal": "Tullie Murrell"
      },
      {
        "family": "Yu",
        "given": "Peter"
      },
      {
        "family": "Præsius",
        "given": "Sebastian"
      },
      {
        "family": "Addair",
        "given": "Travis"
      },
      {
        "family": "Zhong",
        "given": "Jacob"
      },
      {
        "family": "Lipin",
        "given": "Dmitry"
      },
      {
        "family": "Uchida",
        "given": "So"
      },
      {
        "literal": "Shreyas Bapat"
      },
      {
        "family": "Schröter",
        "given": "Hendrik"
      },
      {
        "family": "Dayma",
        "given": "Boris"
      },
      {
        "family": "Karnachev",
        "given": "Alexey"
      },
      {
        "literal": "Akshay Kulkarni"
      },
      {
        "literal": "Shunta Komatsu"
      },
      {
        "literal": "Martin.B"
      },
      {
        "literal": "Jean-Baptiste SCHIRATTI"
      },
      {
        "family": "Mary",
        "given": "Hadrien"
      },
      {
        "family": "Byrne",
        "given": "Donal"
      },
      {
        "literal": "Cristobal Eyzaguirre"
      },
      {
        "literal": "Cinjon"
      },
      {
        "family": "Bakhtin",
        "given": "Anton"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020,
          5,
          15
        ]
      ]
    },
    "abstract": "The lightweight PyTorch wrapper for ML researchers. Scale your models. Write less boilerplate",
    "DOI": "10.5281/zenodo.3828935",
    "publisher": "Zenodo",
    "title": "PyTorchLightning/pytorch-lightning: 0.7.6 release",
    "URL": "https://doi.org/gqc7f9",
    "version": "0.7.6",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.5281/zenodo.3828935"
  },
  {
    "type": "book",
    "id": "UU62HYC6",
    "author": [
      {
        "family": "Consortium",
        "given": "The MONAI"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020,
          12,
          15
        ]
      ]
    },
    "abstract": "MONAI is a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. Its ambitions are: - developing a community of academic, industrial and clinical researchers collaborating on a common foundation; - creating state-of-the-art, end-to-end training workflows for healthcare imaging; - providing researchers with the optimized and standardized way to create and evaluate deep learning models.",
    "DOI": "10.5281/zenodo.4323059",
    "publisher": "Zenodo",
    "title": "Project MONAI",
    "URL": "https://doi.org/gqc7gb",
    "version": "0.4.0",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.5281/zenodo.4323059"
  },
  {
    "type": "article-journal",
    "id": "ExHf2uD2",
    "author": [
      {
        "family": "CHEN",
        "given": "JIJI"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "abstract": "Subject: Data for 3D RCAN Paper Release date: xx-xx-2021 (MM-DD-YYYY)<br> Contacts: Jiji Chen (jiji.chen@nih.gov), Hari Shroff (hari.shroff@nih.gov)<br> Organization: Advanced Imaging and Microscopy (AIM) Resource, National Institutes of Health This data release contains all training and testing data for the 3D RCAN paper published in Nature Methods:<br> 3D residual channel attention networks denoise and sharpen fluorescence microscopy image volumes Data may be found at: https://zenodo.org/record/4624364#.YF3gVq9Kibg Data size: After upzip, the total size is 521 GB. Please leave enough space in the disk before unzip. Data are organized in four categories:<br> - Denoising: It contains all training and testing data for Actin, ER, Golgi, lysosome, Microtubule, Tomm20 Mitochondria and Matrix protein Mitochondria. <br> - Phantom Spheres: It contains training and testing data for synthetic blurred phantom sphere(2, 3 and 4 times). The ground truth is the synthetic phantom sphere without blurring.<br> - Confocal to STED: It contains training and testing data for three different structure shown in the paper (Microtubule, nuclear pore complex and DNA). It also contains live cell data that nucleus stained by SiR for confocal to STED image modality transfer learning. Raw and GT data in the training and testing folder refer to confocal and STED images. <br> - Expansion Microscopy: It contains training and testing data for two different structure shown in the paper. (Microtubule and Tomm20 stained Mitochondria). Raw and GT data in the training and testing folder refer to Synthetic raw and deconvolved expansion microscopy iSIM images.<br> - live cell test data Microscopy: It contains:(1).U2OS cells transfected with matrix protein Mitochondria and Lamp1 labeled lyososome for denoising; (2). Jukat T cells transfected with EMTB-GFP for expansion microscopy.<br> 3D RCAN code is available on our Github repo: https://github.com/AiviaCommunity/3D-RCAN Notes:<br> 1. Gt refers to Ground truth. Raw refers to the raw data.<br> 2. STED Stimulated emission depletion microscopy<br> 3. iSIM: instant structured illumination microscopy",
    "container-title": "Zenodo",
    "DOI": "10.5281/zenodo.4624364",
    "publisher": "Zenodo",
    "title": "3D residual channel attention networks denoise and sharpen fluorescence microscopy image volumes",
    "URL": "https://doi.org/gs9dft",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.5281/zenodo.4624364"
  },
  {
    "type": "dataset",
    "id": "xv2VIyRP",
    "categories": [
      "Light microscopy",
      "Digital Phase Contrast",
      "HeLa cells",
      "Live microscopy"
    ],
    "language": "en",
    "author": [
      {
        "family": "Guiet",
        "given": "Romain"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022,
          2,
          25
        ]
      ]
    },
    "abstract": "<strong>Name</strong>: HeLa “Kyoto” cells under the scope <strong>Microscope</strong>: Perkin Elmer Operetta microscope with a 20x N.A. 0.8 objective and an Andor Zyla 5.5 camera. <strong>Microscopy data type</strong>: The time-lapse datasets were acquired every 15 minutes, for 60 hours. From the individual plan images (channels, time-points, field of view exported by the PerkinElmer software Harmony) multi-dimension images were generated using the Operetta_Importer-0.1.21 with a downscaling of 4. Channel 1 : Low Contrast DPC (Digital Phase Contrast) Channel 2 : High Contrast DPC Channel 3 : Brightfield Channel 4 : EGFP-α-tubulin Channel 5 : mCherry-H2B <strong>File format</strong>: .tif (16-bit) <strong>Image size</strong>: 540x540 (Pixel size: 0.299 nm), 5c, 1z , 240t <strong>Cell type</strong>: HeLa “Kyoto” cells, expressing EGFP-α-tubulin and mCherry-H2B ( Schmitz <em>et al</em>, 2010 ) <strong>Protocol</strong>: Cells were resuspended in <strong>Imaging media</strong> and were seeded in a microscopy grade 96 wells plate ( CellCarrier Ultra 96, Perkin Elmer). The day after seeding, and for 60 hours, images were acquired in 3 wells, in 25 different fields of view, every 15 minutes. <strong>Imaging media</strong>: DMEM red-phenol-free media (FluoroBrite™ DMEM, Gibco) complemented with Fetal Calf Serum and Glutamax. <strong>NOTE: </strong>This dataset was used to automatically generate label images in the following Zenodo entry: <strong> https://doi.org/10.5281/zenodo.6140064</strong> <strong>NOTE: </strong>This dataset was used to train the cellpose models in the following Zenodo entry:<strong> https://doi.org/10.5281/zenodo.6140111</strong>",
    "DOI": "10.5281/zenodo.6139958",
    "publisher": "Zenodo",
    "title": "HeLa \"Kyoto\" cells under the scope",
    "URL": "https://doi.org/gqdkdm",
    "version": "v0",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.5281/zenodo.6139958"
  },
  {
    "type": "dataset",
    "id": "8ywSgqrJ",
    "categories": [
      "Light microscopy",
      "Deep Learning",
      "labels",
      "labeling",
      "StarDist",
      "cellpose"
    ],
    "language": "en",
    "author": [
      {
        "family": "Guiet",
        "given": "Romain"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022,
          2,
          25
        ]
      ]
    },
    "abstract": "<strong>Name</strong>: Automatic labelling of HeLa “Kyoto” cells using Deep Learning tools <strong>Data type</strong>: Microscopy images from the dataset “<strong>HeLa “Kyoto” cells under the scope</strong>”, Brightfield (BF), Digital Phase Contrast (DPC, either “raw” or “square-rooted”), Tubulin and H2B fluorescent channel, paired with their corresponding nuclei or cell/cyto label images. <strong>Labels images</strong>: Labels images were generated using the script <em>“prepare_trainingDataset_cellpose.ijm</em>”. Briefly, for 5 defined time-points (1,10,50,100,150), channels of interest were duplicated, resaved and : - nuclei label images were obtained using StarDist on H2B channel - cell label images were obtained using Cellpose on Tubulin and H2B channels A quick visual inspection of the resulting label images concluded that they were satisfying enough, despite certainly not being perfect. Notes : - This labelling strategy: o will not produce 100% accurate labels, but they might be more reproducible than labels generated by humans and are (definitely) much faster to obtain. o is <strong>NOT a recommended way of generating labels images</strong>, but for educational purposes. - The fluorescent channels are part of the dataset to ease the process of review of the labels and are NOT used for training. We generated the labels from the fluorescent channels to later predict labels from the BF or DPC channels only. As such, the fluorescent channels should not be “reused” with our labels during training. <strong>File format</strong>: .tif (16-bit) <strong>Image size</strong>: 540x540 (Pixel size: 0.299 nm) <strong><em>NOTE</em></strong>: This dataset uses the “HeLa “Kyoto” cells under the scope” dataset (https://doi.org/10.5281/zenodo.6139958) to automatically generate annotations <strong><em>NOTE</em></strong>: This dataset was used to train cellpose models in the following Zenodo entry https://doi.org/10.5281/zenodo.6140111",
    "DOI": "10.5281/zenodo.6140063",
    "publisher": "Zenodo",
    "title": "Automatic labelling of HeLa \"Kyoto\" cells using Deep Learning tools",
    "URL": "https://doi.org/gs8p4s",
    "version": "v0",
    "note": "This CSL Item was generated by Manubot v0.5.5 from its persistent identifier (standard_id).\nstandard_id: doi:10.5281/zenodo.6140063"
  },
  {
    "id": "QmYuUQ5K",
    "type": "paper-conference",
    "title": "Embedding-based Instance Segmentation in Microscopy",
    "container-title": "Proceedings of the Fourth Conference on Medical Imaging with Deep Learning",
    "collection-title": "Proceedings of Machine Learning Research",
    "publisher": "PMLR",
    "page": "399--415",
    "volume": "143",
    "URL": "https://proceedings.mlr.press/v143/lalit21a.html",
    "author": [
      {
        "family": "Lalit",
        "given": "Manan"
      },
      {
        "family": "Tomancak",
        "given": "Pavel"
      },
      {
        "family": "Jug",
        "given": "Florian"
      }
    ],
    "editor": [
      {
        "family": "Heinrich",
        "given": "Mattias"
      },
      {
        "family": "Dou",
        "given": "Qi"
      },
      {
        "family": "de Bruijne",
        "given": "Marleen"
      },
      {
        "family": "Lellmann",
        "given": "Jan"
      },
      {
        "family": "Schläfer",
        "given": "Alexander"
      },
      {
        "family": "Ernst",
        "given": "Floris"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2022",
          6,
          22
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: embedseg"
  },
  {
    "id": "vzOBQiEH",
    "type": "webpage",
    "title": "Imaginaire",
    "URL": "https://github.com/NVlabs/imaginaire",
    "publisher": "Github",
    "author": [
      {
        "family": "Contributors",
        "given": "Imaginaire"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          12,
          12
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: imaginaire"
  },
  {
    "id": "17WhsEZko",
    "type": "webpage",
    "title": "Pyrallis - Simple Configuration with Dataclasses",
    "URL": "https://github.com/eladrich/pyrallis",
    "publisher": "Github",
    "author": [
      {
        "family": "Richardson",
        "given": "Elad"
      },
      {
        "family": "Weiss",
        "given": "Ido"
      },
      {
        "family": "Feldman",
        "given": "Yair"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          12,
          12
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: pyrallis"
  },
  {
    "id": "vm45dW9e",
    "type": "webpage",
    "title": "The hiPSC single-cell image dataset",
    "URL": "https://open.quiltdata.com/b/allencell/packages/aics/hipsc_single_cell_image_dataset",
    "author": [
      {
        "family": "Chen",
        "given": "Jianxu"
      },
      {
        "family": "Metzler",
        "given": "Kimverly"
      },
      {
        "family": "Contributors",
        "given": "Allen Institute"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          12,
          18
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: single_cell_dataset"
  },
  {
    "id": "cjAzGPun",
    "type": "webpage",
    "title": "Deep Learning-Inferred Multiplex ImmunoFluorescence for Immunohistochemical Image Quantification",
    "URL": "https://zenodo.org/record/4751737#.Y9gbv4HMLVZ",
    "publisher": "Zenodo",
    "author": [
      {
        "family": "Ghahremani",
        "given": "Parmida"
      },
      {
        "family": "Li",
        "given": "Yanyun"
      },
      {
        "family": "Kaufman",
        "given": "Arie"
      },
      {
        "family": "Rami",
        "given": "Vanguri"
      },
      {
        "family": "Greenwald",
        "given": "Noah"
      },
      {
        "family": "Angelo",
        "given": "Michael"
      },
      {
        "family": "Hollmann",
        "given": "Travis"
      },
      {
        "family": "Nadeem",
        "given": "Saad"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          12,
          18
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: stain_transformation"
  },
  {
    "id": "qzeQFRn9",
    "type": "paper-conference",
    "title": "Averaging Weights Leads to Wider Optima and Better Generalization",
    "container-title": "34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018",
    "page": "876--885",
    "URL": "http://auai.org/uai2018/proceedings/papers/313.pdf",
    "author": [
      {
        "family": "Izmailov",
        "given": "Pavel"
      },
      {
        "family": "Podoprikhin",
        "given": "Dmitrii"
      },
      {
        "family": "Garipov",
        "given": "Timur"
      },
      {
        "family": "Vetrov",
        "given": "Dmitry"
      },
      {
        "family": "Wilson",
        "given": "Andrew Gordon"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2022",
          6,
          22
        ]
      ]
    },
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: swatrain"
  }
]
